{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f97c83f0-5ee2-40c0-a762-cd4cc45fcc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ebooklib import epub\n",
    "import ebooklib\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "\n",
    "class EPUBProcessor:\n",
    "    \"\"\"Process EPUB files into structured content with proper handling of chapters, \n",
    "    footnotes, and references.\"\"\"\n",
    "    \n",
    "    def __init__(self, epub_path: str):\n",
    "        \"\"\"Initialize the processor with an EPUB file path.\n",
    "        \n",
    "        Args:\n",
    "            epub_path (str): Path to the EPUB file\n",
    "        \"\"\"\n",
    "        self.epub_path = epub_path\n",
    "        self.book = None\n",
    "        self.chapters = []\n",
    "        self.chapters_html = []\n",
    "        self.book_by_chapters = {}\n",
    "        self.notes_by_chapter = {}\n",
    "        \n",
    "    def load_epub(self) -> None:\n",
    "        \"\"\"Load and parse the EPUB file.\"\"\"\n",
    "        try:\n",
    "            self.book = epub.read_epub(self.epub_path)\n",
    "            self._extract_chapters()\n",
    "            self._parse_chapters()\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error loading EPUB file: {str(e)}\")\n",
    "\n",
    "    def _extract_chapters(self) -> None:\n",
    "        \"\"\"Extract chapters from the EPUB file.\"\"\"\n",
    "        item_label_number = {\n",
    "            name: getattr(ebooklib, name) \n",
    "            for name in dir(ebooklib) if name.startswith('ITEM_')\n",
    "        }\n",
    "        \n",
    "        self.chapters = [\n",
    "            item for item in self.book.items \n",
    "            if item.get_type() == item_label_number[\"ITEM_DOCUMENT\"]\n",
    "        ]\n",
    "\n",
    "    def _parse_chapters(self) -> None:\n",
    "        \"\"\"Parse chapters into BeautifulSoup objects.\"\"\"\n",
    "        self.chapters_html = []\n",
    "        for chapter in self.chapters:\n",
    "            content = chapter.get_content()\n",
    "            parsed_content = BeautifulSoup(content, 'html.parser')\n",
    "            text = parsed_content.get_text()\n",
    "            \n",
    "            if bool(text.strip()):\n",
    "                self.chapters_html.append(parsed_content)\n",
    "\n",
    "    def extract_elements(self, chapter_soup: BeautifulSoup) -> List[Tuple[str, Any]]:\n",
    "        \"\"\"Extract elements from a chapter in sequential order, including classes and IDs.\n",
    "        \n",
    "        Args:\n",
    "            chapter_soup (BeautifulSoup): BeautifulSoup object of chapter content\n",
    "            \n",
    "        Returns:\n",
    "            List[Tuple[str, Any]]: List of tuples containing element type, content, classes, and IDs\n",
    "        \"\"\"\n",
    "        elements = []\n",
    "        for element in chapter_soup.find_all(['h1', 'h2', 'p', 'a', 'img', 'blockquote']):\n",
    "            # Determine element type\n",
    "            if element.name in ['h1', 'h2']:\n",
    "                element_type = 'title'\n",
    "            elif element.name == 'p':\n",
    "                element_type = 'paragraph'\n",
    "            elif element.name == 'a' and element.get('class') and any('Reference' in c for c in element['class']):\n",
    "                element_type = 'note'\n",
    "            elif element.name == 'img':\n",
    "                element_type = 'media'\n",
    "            elif element.name == 'blockquote':\n",
    "                element_type = 'quote'\n",
    "            else:\n",
    "                continue\n",
    "    \n",
    "            # Fetch classes and IDs\n",
    "            element_classes = element.get('class', [])  # Returns a list of classes or an empty list\n",
    "            element_id = element.get('id', None)       # Returns the ID or None\n",
    "    \n",
    "            # Append element type, content, classes, and ID\n",
    "            elements.append((element_type, element, element_classes, element_id))\n",
    "        \n",
    "        return elements\n",
    "\n",
    "    def process_chapters(self) -> List[List[Tuple[str, Any]]]:\n",
    "        \"\"\"Process all chapters and extract their elements.\n",
    "        \n",
    "        Returns:\n",
    "            List[List[Tuple[str, Any]]]: List of processed chapters\n",
    "        \"\"\"\n",
    "        return [self.extract_elements(chapter_soup) for chapter_soup in self.chapters_html]\n",
    "\n",
    "    def parse_notes(self, notes_chapter_index: int) -> Dict[int, Dict[str, str]]:\n",
    "        \"\"\"Parse notes from the notes chapter.\n",
    "        \n",
    "        Args:\n",
    "            notes_chapter_index (int): Index of the notes chapter\n",
    "            \n",
    "        Returns:\n",
    "            Dict[int, Dict[str, str]]: Dictionary of notes by chapter\n",
    "        \"\"\"\n",
    "        notes_by_chapter = {}\n",
    "        chapter_notes = {}\n",
    "        aux = []\n",
    "        chapter_index = 0\n",
    "        \n",
    "        for entry in self.process_chapters()[notes_chapter_index]:\n",
    "            if entry[0] == 'title':\n",
    "                if aux:\n",
    "                    notes_by_chapter[chapter_index] = chapter_notes\n",
    "                    aux = []\n",
    "                    chapter_notes = {}\n",
    "                    chapter_index += 1\n",
    "            elif entry[0]:\n",
    "                if (len(aux)+1) % 2 == 0:\n",
    "                    aux.append(\"\")\n",
    "                else:\n",
    "                    reference = entry[1].get_text()\n",
    "                    reference_number = f\"[{(len(aux)//2)+1}]\"\n",
    "                    aux.append(reference)\n",
    "                    chapter_notes[reference_number] = reference\n",
    "                    \n",
    "        if aux:\n",
    "            notes_by_chapter[chapter_index] = chapter_notes\n",
    "            \n",
    "        return notes_by_chapter\n",
    "\n",
    "    def fill_notes(self, chapter_index: int, current_footnote_index: int, \n",
    "                  updated_chapters: List[List[Tuple[str, Any]]], notes_by_chapter: Dict[int, Dict[str, str]], \n",
    "                  chapter_indexes: List[int], notes_indexes: List[int]) -> Tuple[int, List[List[Tuple[str, Any]]]]:\n",
    "        \"\"\"Fill in notes for a chapter.\n",
    "        \n",
    "        Args:\n",
    "            chapter_index (int): Index of the chapter\n",
    "            current_footnote_index (int): Current footnote index\n",
    "            updated_chapters (List[List[Tuple[str, Any]]]): Chapters with updates\n",
    "            notes_by_chapter (Dict[int, Dict[str, str]]): Notes organized by chapter\n",
    "            chapter_indexes (List[int]): List of chapter indexes\n",
    "            notes_indexes (List[int]): List of notes indexes\n",
    "            \n",
    "        Returns:\n",
    "            Tuple[int, List[List[Tuple[str, Any]]]]: Updated footnote index and chapters\n",
    "        \"\"\"\n",
    "        chapter = updated_chapters[chapter_indexes[chapter_index]]\n",
    "        chapter_notes = notes_by_chapter[notes_indexes[chapter_index]]\n",
    "        \n",
    "        note_id_cnt = 1\n",
    "        last_paragraph_with_footnote = None\n",
    "        footnote_paragraph_map = []\n",
    "        note_paragraph_map = []\n",
    "        footnote_contents = {}\n",
    "        note_contents = {}\n",
    "        \n",
    "        # Collect footnotes and notes\n",
    "        for i, item in enumerate(chapter):\n",
    "            note_id = f\"[{note_id_cnt}]\"\n",
    "            if item[0] == 'paragraph':\n",
    "                if '[*]' in item[1].get_text():\n",
    "                    last_paragraph_with_footnote = i\n",
    "                if note_id in item[1].get_text():\n",
    "                    note_paragraph_map.append((i, note_id))\n",
    "            elif item[0] == \"note\":\n",
    "                if note_id in chapter_notes.keys():\n",
    "                    note_contents[note_id] = chapter_notes[note_id]\n",
    "                    note_id_cnt += 1\n",
    "                else:\n",
    "                    footnote_content = f\"([*] -> '''{updated_chapters[current_footnote_index][0][1].get_text()}'''\"\n",
    "                    footnote_contents[last_paragraph_with_footnote] = footnote_content\n",
    "                    footnote_paragraph_map.append((current_footnote_index, last_paragraph_with_footnote))\n",
    "                    current_footnote_index += 1\n",
    "\n",
    "        # Process footnotes and notes\n",
    "        for (_, para_index) in footnote_paragraph_map:\n",
    "            if para_index is not None and para_index < len(chapter):\n",
    "                tag = chapter[para_index][1]\n",
    "                text = tag.string if tag.string else tag.get_text()\n",
    "                footnote_content = footnote_contents[para_index]\n",
    "                new_text = text.replace('[*]', f\" ([*] : ' {footnote_content} ') \")\n",
    "                tag.string = new_text\n",
    "                chapter[para_index] = ('paragraph', tag)\n",
    "\n",
    "        for (para_index, note_id) in note_paragraph_map:\n",
    "            if note_id in note_contents:\n",
    "                tag = chapter[para_index][1]\n",
    "                text = tag.string if tag.string else tag.get_text()\n",
    "                note_content = note_contents[note_id]\n",
    "                new_text = text.replace(note_id, f\" ({note_id} : ' {note_content} ') \")\n",
    "                tag.string = new_text\n",
    "                chapter[para_index] = ('paragraph', tag)\n",
    "\n",
    "        # Remove original note items\n",
    "        chapter = [(type_, content) for type_, content in chapter if type_ != 'note']\n",
    "        \n",
    "        updated_chapters[chapter_indexes[chapter_index]] = chapter\n",
    "        return current_footnote_index, updated_chapters\n",
    "\n",
    "    def organize_chapters(self, intro_index: int, first_chapter_index: int, \n",
    "                        last_chapter_index: int, processed_chapters: List[List[Tuple[str, Any]]]) -> Dict[str, List[Tuple[str, Any]]]:\n",
    "        \"\"\"Organize chapters into a dictionary with proper titles.\n",
    "        \n",
    "        Args:\n",
    "            intro_index (int): Index of introduction\n",
    "            first_chapter_index (int): Index of first chapter\n",
    "            last_chapter_index (int): Index of last chapter\n",
    "            processed_chapters (List[List[Tuple[str, Any]]]): Processed chapter content\n",
    "            \n",
    "        Returns:\n",
    "            Dict[str, List[Tuple[str, Any]]]: Organized chapters by title\n",
    "        \"\"\"\n",
    "        book_by_chapters = {}\n",
    "        chapter_indexes = [intro_index]\n",
    "        chapter_indexes.extend(list(range(first_chapter_index, last_chapter_index + 1)))\n",
    "        \n",
    "        for chapter_index in chapter_indexes:\n",
    "            if chapter_index == intro_index or chapter_index == last_chapter_index:\n",
    "                # Introduction has the title as first\n",
    "                book_by_chapters[processed_chapters[chapter_index][0][1].get_text()] = processed_chapters[chapter_index][1:]\n",
    "            else:\n",
    "                # Only has proper title in 3rd pos\n",
    "                book_by_chapters[processed_chapters[chapter_index][2][1].get_text()] = processed_chapters[chapter_index][2:]\n",
    "                \n",
    "        return book_by_chapters\n",
    "\n",
    "    def export_json(self, filename: str) -> None:\n",
    "        \"\"\"Export the processed book to JSON.\n",
    "        \n",
    "        Args:\n",
    "            filename (str): Output JSON filename\n",
    "        \"\"\"\n",
    "        def tag_to_dict(tag):\n",
    "            \"\"\"Convert a BeautifulSoup Tag to a dictionary.\"\"\"\n",
    "            if not isinstance(tag, BeautifulSoup.Tag):\n",
    "                return str(tag)\n",
    "            \n",
    "            return {\n",
    "                'name': tag.name,\n",
    "                'attrs': dict(tag.attrs),\n",
    "                'contents': [tag_to_dict(child) for child in tag.contents]\n",
    "            }\n",
    "        \n",
    "        serializable_dict = {}\n",
    "        for title, content in self.book_by_chapters.items():\n",
    "            serializable_dict[title] = [\n",
    "                (type_info, tag_to_dict(tag)) if isinstance(tag, BeautifulSoup.Tag) else (type_info, tag)\n",
    "                for type_info, tag in content\n",
    "            ]\n",
    "        \n",
    "        with open(filename, 'w', encoding='utf-8') as fp:\n",
    "            json.dump(serializable_dict, fp, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5f063ac1-be18-48df-a65c-d3437e9cf177",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = EPUBProcessor(\"aron.epub\")\n",
    "processor.load_epub()\n",
    "\n",
    "# Process chapters\n",
    "processed_chapters = processor.process_chapters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f6f0fefb-3bbd-424e-a789-b4dccce3a4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Function to summarize text using ChatGPT\n",
    "def helpful_aid( messages):\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": \"phi-4@q6_k\", \n",
    "        \"messages\": messages,\n",
    "    }\n",
    "    \n",
    "    \n",
    "    response = requests.post(\n",
    "        \"http://localhost:24236/v1/chat/completions\",\n",
    "        headers={\"Content-Type\": \"application/json\"},\n",
    "        json=payload,\n",
    "        timeout=15\n",
    "    )\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        summary = result.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\").strip()\n",
    "        return summary\n",
    "    else:\n",
    "        raise Exception()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "07d28db5-918b-435c-8358-fb2de6a9d4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 Chapters\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "print(f\"{len(processed_chapters)} Chapters\")\n",
    "\n",
    "chapters = \"\"\n",
    "\n",
    "for i, c in enumerate(processed_chapters):\n",
    "    chapters += f\"[{i}] ({c[0][0]}) -> {c[0][1]}\"\n",
    "\n",
    "SYSTEM_INSTRUCTION = \"You map jsons and only return the json structure without any tags or text beside it. dont use ```json and ``` around the result.\"\n",
    "messages=[{\"role\": \"system\", \"content\": SYSTEM_INSTRUCTION },\n",
    "          {\"role\": \"user\", \"content\": f\"Only return me a json without any tags around it mapping the index [i] to the chapter / section of the book. Here is the listing: {chapters}. Dont return ```json or ```, nor any \\n\"}]\n",
    "\n",
    "json_str = helpful_aid(messages)\n",
    "json_str = json_str.replace(\"```json\", \"\").replace(\"```\", \"\")\n",
    "\n",
    "chapter_dict = json.loads(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2910acff-90c5-441a-a093-8ea13716e97d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 'The Opium of the Intellectuals',\n",
       " '1': 'FOREWORD TO THE TRANSACTION EDITION',\n",
       " '2': 'INTRODUCTION TO THE TRANSACTION EDITION',\n",
       " '3': 'FOREWORD',\n",
       " '4': 'PART ONE',\n",
       " '5': 'CHAPTER I',\n",
       " '6': 'CHAPTER II',\n",
       " '7': 'CHAPTER III',\n",
       " '8': 'CONCERNING POLITICAL OPTIMISM',\n",
       " '9': 'PART II',\n",
       " '10': 'CHAPTER IV',\n",
       " '11': 'CHAPTER V',\n",
       " '12': 'CHAPTER VI',\n",
       " '13': 'THE CONTROL OF HISTORY',\n",
       " '14': 'PART THREE',\n",
       " '15': 'CHAPTER VII',\n",
       " '16': 'CHAPTER VIII',\n",
       " '17': 'CHAPTER IX',\n",
       " '18': 'THE DESTINY OF THE INTELLECTUALS',\n",
       " '19': 'CONCLUSION',\n",
       " '20': 'APPENDIX',\n",
       " '21': 'INDEX'}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chapter_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1a613153-0546-4a74-b500-e3f8c0e608b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtxt_body -> 1188\n",
      "gtxt_lineated -> 3\n",
      "gtxt_quote -> 5\n",
      "gtxt_heading -> 35\n",
      "gtxt_h1_heading -> 41\n",
      "gtxt_footnote -> 52\n",
      "gtxt_list_entry -> 6\n"
     ]
    }
   ],
   "source": [
    "classes = {}\n",
    "\n",
    "for cI, c in enumerate(processed_chapters):\n",
    "    for sI, s in enumerate(c):\n",
    "        for cla in s[2]:\n",
    "            identifier = (cI, sI)\n",
    "            if cla in classes.keys():\n",
    "                classes[cla].append(identifier)\n",
    "            else:\n",
    "                classes[cla] = [identifier]\n",
    "for k in classes:\n",
    "    print(f\"{k} -> {len(classes[k])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "042ae5ce-f715-455e-b900-dd82d807a303",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cI, c in enumerate(processed_chapters):\n",
    "    for sI, s in enumerate(c):\n",
    "        classes_tags = s[2]\n",
    "        if 'gtxt_heading' in classes_tags or 'gtxt_h1_heading' in classes_tags:\n",
    "            typ = 'title'\n",
    "            text = processed_chapters[cI][sI][1].get_text()\n",
    "\n",
    "            processed_chapters[cI][sI] = (typ, text)\n",
    "            \n",
    "        elif 'gtxt_footnote' in s[2]:\n",
    "            typ = 'footnote'\n",
    "            text = processed_chapters[cI][sI][1].get_text()\n",
    "\n",
    "            processed_chapters[cI][sI] = (typ, text)\n",
    "\n",
    "        elif 'gtxt_quote' in s[2]:\n",
    "            typ = s[0]\n",
    "            text = \"\\n<quote>\\n\" + processed_chapters[cI][sI][1].get_text() + \"\\n<quote>\\n\"\n",
    "\n",
    "            processed_chapters[cI][sI] = (typ, text)\n",
    "\n",
    "        elif 'gtxt_list_entry' in s[2]:\n",
    "            typ = s[0]\n",
    "            text = \"\\t\" + processed_chapters[cI][sI][1].get_text()\n",
    "\n",
    "            processed_chapters[cI][sI] = (typ, text)\n",
    "        else:\n",
    "            processed_chapters[cI][sI] = (s[0], s[1].get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "82793dd3-bc09-4c7a-9df0-88f1d5752e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter 20 Section 97 -> \t2. This doctrine, which is axiomatic for the author of  et le néant, cannot be attributed without reservation to the author of La Phénoménologie de perception. \n"
     ]
    }
   ],
   "source": [
    "lin = classes['gtxt_list_entry'][1]\n",
    "print(f\"Chapter {lin[0]} Section {lin[1]} -> {processed_chapters[lin[0]][lin[1]][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "62716f2d-1e66-4f73-99c7-5f3eda3eac1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'footnote', 'paragraph', 'title'}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([s[0] for s in sole_chapter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741acc3b-d6e9-4d6f-80b5-bb0aaafd88e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "SYSTEM_INSTRUCTION = \"You are a helpful assistant that summarizes paragraphs from books. Return markdown formatting without any tags around it.\"\n",
    "# Function to summarize text using ChatGPT\n",
    "def summarize_text_LMSTUDIO(text, messages, tries=3):\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": \"phi-4@q6_k\", \n",
    "        \"messages\": messages,\n",
    "    }\n",
    "    \n",
    "    \n",
    "\n",
    "    while tries > 0:\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                \"http://localhost:24236/v1/chat/completions\",\n",
    "                headers={\"Content-Type\": \"application/json\"},\n",
    "                json=payload,\n",
    "                timeout=15\n",
    "            )\n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                summary = result.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\").strip()\n",
    "                return summary, messages\n",
    "            else:\n",
    "                tries -=1 \n",
    "        except:\n",
    "            tries -=1\n",
    "\n",
    "    raise Exception(\"Tries ran out\")\n",
    "\n",
    "\n",
    "def summarize_text(text, messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_INSTRUCTION },\n",
    "            {\"role\": \"system\", \"content\": f\"Tell the user he forgot to set the messages!\"}\n",
    "        ]):\n",
    "    return summarize_text_LMSTUDIO(text, messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ef6b6fa-5d40-4119-9a0c-771cb2dff909",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Opium\"\n",
    "\n",
    "# FILL NOTES (considering paragraph)\n",
    "# Look for *number put second in the first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f4220fd-daa8-45c5-9914-4c79aa0ef014",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Export to JSON and HTML\n",
    "processor.export_json(\"book_processed.json\")\n",
    "for title, content in processor.book_by_chapters.items():\n",
    "    processor.export_html(title, content, f\"{title.lower().replace(' ', '_')}.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pub",
   "language": "python",
   "name": "env_pub"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
