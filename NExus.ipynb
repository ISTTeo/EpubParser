{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e31cfd76-a19f-430e-99c3-fa5b6e063b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from EpubProcessor import EPUBProcessor\n",
    "from hierarchical_summarizer import EPUBSummarizerHierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73c7e544-d7d2-46f4-999f-6415769ffc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0] (paragraph) -> <p class=\"crts\" id=\"ji_38\" lang=\"en-US\"><a id=\"page-iv\"></a>Copyright © 2023 by Daron Acemoglu and Simon Johnson</p>\n",
      "[1] (title) -> <h1 class=\"toc-title\" id=\"ji_3077\">Contents</h1>\n",
      "[2] (paragraph) -> <p class=\"ded\" id=\"ji_68\" lang=\"en-US\"><a id=\"page-v\"></a>Daron:</p>\n",
      "[3] (paragraph) -> <p class=\"calibre9\"><strong class=\"calibre2\">Explore book giveaways, sneak peeks, deals, and more.</strong></p>\n",
      "[4] (paragraph) -> <p class=\"ep\" id=\"ji_72\" lang=\"en-US\"><a id=\"page-vi\"></a>If we combine our machine-potentials of a factory with the valuation of human beings on which our present factory system is based, we are in for an industrial revolution of unmitigated cruelty. We must be willing to deal in facts rather than in fashionable ideologies if we wish to get through this period unharmed.</p>\n",
      "[5] (paragraph) -> <p class=\"cn\" id=\"ji_93\" lang=\"en-US\"><a id=\"page-1\"></a><a href=\"toc.xhtml#toc8\" id=\"toc_8\"><span class=\"charoverride\" lang=\"\">Prologue</span></a></p>\n",
      "[6] (paragraph) -> <p class=\"cn\" id=\"ji_128\" lang=\"en-US\"><a id=\"page-9\"></a><a href=\"toc.xhtml#toc9\" id=\"toc_9\">1</a></p>\n",
      "[7] (paragraph) -> <p class=\"cn\" id=\"ji_252\" lang=\"en-US\"><a id=\"page-39\"></a><a href=\"toc.xhtml#toc10\" id=\"toc_10\">2</a></p>\n",
      "[8] (paragraph) -> <p class=\"cn\" id=\"ji_399\" lang=\"en-US\"><a id=\"page-67\"></a><a href=\"toc.xhtml#toc11\" id=\"toc_11\">3</a></p>\n",
      "[9] (paragraph) -> <p class=\"cn\" id=\"ji_552\" lang=\"en-US\"><a id=\"page-99\"></a><a href=\"toc.xhtml#toc12\" id=\"toc_12\">4</a></p>\n",
      "[10] (paragraph) -> <p class=\"cn\" id=\"ji_769\" lang=\"en-US\"><a id=\"page-141\"></a><a href=\"toc.xhtml#toc13\" id=\"toc_13\">5</a></p>\n",
      "[11] (paragraph) -> <p class=\"cn\" id=\"ji_930\" lang=\"en-US\"><a id=\"page-175\"></a><a href=\"toc.xhtml#toc14\" id=\"toc_14\">6</a></p>\n",
      "[12] (paragraph) -> <p class=\"cn\" id=\"ji_1122\" lang=\"en-US\"><a id=\"page-213\"></a><a href=\"toc.xhtml#toc15\" id=\"toc_15\">7</a></p>\n",
      "[13] (paragraph) -> <p class=\"cn\" id=\"ji_1310\" lang=\"en-US\"><a id=\"page-253\"></a><a href=\"toc.xhtml#toc16\" id=\"toc_16\">8</a></p>\n",
      "[14] (paragraph) -> <p class=\"cn\" id=\"ji_1495\" lang=\"en-US\"><a id=\"page-297\"></a><a href=\"toc.xhtml#toc17\" id=\"toc_17\">9</a></p>\n",
      "[15] (paragraph) -> <p class=\"cn\" id=\"ji_1664\" lang=\"en-US\"><a id=\"page-339\"></a><a href=\"toc.xhtml#toc18\" id=\"toc_18\">10</a></p>\n",
      "[16] (paragraph) -> <p class=\"cn\" id=\"ji_1851\" lang=\"en-US\"><a id=\"page-383\"></a><a href=\"toc.xhtml#toc19\" id=\"toc_19\">11</a></p>\n",
      "[17] (media) -> <img alt=\"image\" class=\"calibre1\" src=\"../images/Art_insert001.jpg\"/>\n",
      "[18] (media) -> <img alt=\"image\" class=\"calibre1\" src=\"../images/Art_insert002.jpg\"/>\n",
      "[19] (media) -> <img alt=\"image\" class=\"calibre10\" src=\"../images/Art_insert003.jpg\"/>\n",
      "[20] (media) -> <img alt=\"image\" class=\"calibre10\" src=\"../images/Art_insert004.jpg\"/>\n",
      "[21] (media) -> <img alt=\"image\" class=\"calibre1\" src=\"../images/Art_insert005.jpg\"/>\n",
      "[22] (media) -> <img alt=\"image\" class=\"calibre10\" src=\"../images/Art_insert006.jpg\"/>\n",
      "[23] (media) -> <img alt=\"image\" class=\"calibre1\" src=\"../images/Art_insert007.jpg\"/>\n",
      "[24] (media) -> <img alt=\"image\" class=\"calibre10\" src=\"../images/Art_insert008.jpg\"/>\n",
      "[25] (media) -> <img alt=\"image\" class=\"calibre1\" src=\"../images/Art_insert009.jpg\"/>\n",
      "[26] (media) -> <img alt=\"image\" class=\"calibre10\" src=\"../images/Art_insert010.jpg\"/>\n",
      "[27] (media) -> <img alt=\"image\" class=\"calibre10\" src=\"../images/Art_insert011.jpg\"/>\n",
      "[28] (media) -> <img alt=\"image\" class=\"calibre10\" src=\"../images/Art_insert012.jpg\"/>\n",
      "[29] (media) -> <img alt=\"image\" class=\"calibre10\" src=\"../images/Art_insert013.jpg\"/>\n",
      "[30] (media) -> <img alt=\"image\" class=\"calibre10\" src=\"../images/Art_insert014.jpg\"/>\n",
      "[31] (media) -> <img alt=\"image\" class=\"calibre10\" src=\"../images/Art_insert015.jpg\"/>\n",
      "[32] (media) -> <img alt=\"image\" class=\"calibre10\" src=\"../images/Art_insert016.jpg\"/>\n",
      "[33] (media) -> <img alt=\"image\" class=\"calibre10\" src=\"../images/Art_insert017.jpg\"/>\n",
      "[34] (media) -> <img alt=\"image\" class=\"calibre1\" src=\"../images/Art_insert018.jpg\"/>\n",
      "[35] (media) -> <img alt=\"image\" class=\"calibre10\" src=\"../images/Art_insert019.jpg\"/>\n",
      "[36] (media) -> <img alt=\"image\" class=\"calibre10\" src=\"../images/Art_insert020.jpg\"/>\n",
      "[37] (media) -> <img alt=\"image\" class=\"calibre1\" src=\"../images/Art_insert021.jpg\"/>\n",
      "[38] (media) -> <img alt=\"image\" class=\"calibre10\" src=\"../images/Art_insert022.jpg\"/>\n",
      "[39] (media) -> <img alt=\"image\" class=\"calibre10\" src=\"../images/Art_insert023.jpg\"/>\n",
      "[40] (media) -> <img alt=\"image\" class=\"calibre10\" src=\"../images/Art_insert024.jpg\"/>\n",
      "[41] (media) -> <img alt=\"image\" class=\"calibre1\" src=\"../images/Art_insert025.jpg\"/>\n",
      "[42] (media) -> <img alt=\"image\" class=\"calibre10\" src=\"../images/Art_insert026.jpg\"/>\n",
      "[43] (media) -> <img alt=\"image\" class=\"calibre10\" src=\"../images/Art_insert027.jpg\"/>\n",
      "[44] (media) -> <img alt=\"image\" class=\"calibre10\" src=\"../images/Art_insert028.jpg\"/>\n",
      "[45] (media) -> <img alt=\"image\" class=\"calibre10\" src=\"../images/Art_insert029.jpg\"/>\n",
      "[46] (media) -> <img alt=\"image\" class=\"calibre10\" src=\"../images/Art_insert030.jpg\"/>\n",
      "[47] (media) -> <img alt=\"image\" class=\"calibre10\" src=\"../images/Art_insert031.jpg\"/>\n",
      "[48] (media) -> <img alt=\"image\" class=\"calibre1\" src=\"../images/Art_insert032.jpg\"/>\n",
      "[49] (media) -> <img alt=\"image\" class=\"calibre1\" src=\"../images/Art_insert033.jpg\"/>\n",
      "[50] (media) -> <img alt=\"image\" class=\"calibre1\" src=\"../images/Art_insert034.jpg\"/>\n",
      "[51] (title) -> <h1 class=\"bmh\" id=\"ji_2084\" lang=\"en-US\"><a id=\"page-423\"></a><a href=\"toc.xhtml#toc54\" id=\"toc_54\">Bibliographic Essay</a></h1>\n",
      "[52] (title) -> <h1 class=\"bmh\" id=\"ji_2335\" lang=\"en-US\"><a id=\"page-475\"></a><a href=\"toc.xhtml#toc55\" id=\"toc_55\">References</a></h1>\n",
      "[53] (title) -> <h1 class=\"bmh\" id=\"ji_3021\" lang=\"en-US\"><a id=\"page-517\"></a><a href=\"toc.xhtml#toc56\" id=\"toc_56\">Acknowledgments</a></h1>\n",
      "[54] (paragraph) -> <p class=\"calibre9\"><strong class=\"calibre2\">Discover Your Next Great Read</strong></p>\n",
      "[55] (title) -> <h1 class=\"bmh\" id=\"ji_3031\" lang=\"en-US\"><a id=\"page-519\"></a><a href=\"toc.xhtml#toc57\" id=\"toc_57\">Image Credits</a></h1>\n",
      "[56] (title) -> <h1 class=\"bmh\" id=\"ji_3068\"><a href=\"toc.xhtml#toc58\" id=\"toc_58\"></a></h1>\n",
      "[57] (paragraph) -> <p class=\"adh\" id=\"ji_31\" lang=\"en-US\"><a id=\"page-II\"></a><a href=\"toc.xhtml#toc2a\" id=\"toc_2a\">ALSO BY DARON ACEMOGLU</a></p>\n",
      "[58] (title) -> <h1 class=\"bmh\" id=\"ji_1\" lang=\"en-US\"><a id=\"page-a\"></a><a href=\"toc.xhtml#toc1\" id=\"toc_1\"><span class=\"charoverride2\" lang=\"\">Praise for </span><span class=\"ital6\" lang=\"\">Power and Progress</span></a></h1>\n"
     ]
    }
   ],
   "source": [
    "processor = EPUBProcessor(\"./books/nexus.epub\")\n",
    "processor.A_load_epub()\n",
    "p = processor.B_parse_chapters()\n",
    "processor.display_parsed_chapter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "959ad879-71bf-42a6-8467-1da8c4d78bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cn-chap-pg', 'crt', 'fmp', 'tocpt', '_idGenObjectAttribute-7', 'dedf-ded-pg', 'tocbm-alt', 'exts', 'p', 'fmt-pro-pg', 'ct-epl-pg', 'crtf', 'fmt-toc-pg', 'pcon', 'bmh1', 'crtf-crt-pg', 'ded', '_idGenObjectAttribute-8', 'pt', 'fmpf', 'fmpaft', '_idGenObjectAttribute-11', 'illcapf', 'tocct', '_idGenObjectAttribute-6', '_idGenObjectAttribute-9', 'extl', 'ul', 'tocfm', 'acmh-ac-pg', 'aclf', 'orn3', 'orn2', '_idGenObjectAttribute-4', 'paft', 'h1-alt', 'art-text', 'acl', 'atat-ata-pg', 'ull', 'extf', '_idGenObjectAttribute-10', 'fmh1', 'ct', 'h1', 'en', 'tocbm', '_idGenObjectAttribute-5', 'ulf', 'pn-part-pg', 'pf', 'bmt-ack-pg', 'bmt-nt-pg', 'ataf', 'en-alt3', 'ornfmbm', 'bmpf', 'en-alt1', 'disclaimer'}\n"
     ]
    }
   ],
   "source": [
    "classes = []\n",
    "for cI, c in enumerate(processor.parsed_chapters):\n",
    "        for sI, s in enumerate(c):\n",
    "            classes.extend(s[2])\n",
    "\n",
    "print(set(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da64931b-0f99-43ac-a6a6-52d5ebea5866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h1-alt', 'bmh1', 'fmh1', 'h1']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inner_titles_tags = ['fmh1'] + [c for c in classes if 'h1' in c]\n",
    "inner_titles_tags = list(set(inner_titles_tags))\n",
    "inner_titles_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e60389b4-d3f4-4e75-8721-c82d3d9d7667",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_titles = ['fmt-pro-pg', 'cn-chap-pg', 'ct']\n",
    "part_titles = ['pt', 'pn-part-pg', 'bmt-nt-pg', 'ct-epl-pg']\n",
    "\n",
    "def set_section_types_by_classes_and_clean_text(self):\n",
    "    for cI, c in enumerate(self.parsed_chapters):\n",
    "        for sI, s in enumerate(c):\n",
    "            classes_tags = s[2]\n",
    "\n",
    "            if any(tag in classes_tags for tag in (inner_titles_tags + chapter_titles + part_titles)):\n",
    "                typ = 'title'\n",
    "                text = self.parsed_chapters[cI][sI][1].get_text()\n",
    "                if any(tag in classes_tags for tag in (part_titles)):\n",
    "                    subtype = 'part'\n",
    "                elif any(tag in classes_tags for tag in (chapter_titles)):\n",
    "                    subtype = 'chapter'\n",
    "                elif inner_titles_tags:\n",
    "                    print(text)\n",
    "                    subtype = 'subchapter'\n",
    "                self.parsed_chapters[cI][sI] = (typ, text, subtype, s[1])\n",
    "            else:\n",
    "                self.parsed_chapters[cI][sI] = (s[0], s[1].get_text(), s[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c068ecc2-05be-479e-9733-a1a99790e040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE NAIVE VIEW OF INFORMATION\n",
      "GOOGLE VERSUS GOETHE\n",
      "WEAPONIZING INFORMATION\n",
      "THE ROAD AHEAD\n",
      "WHAT IS TRUTH?\n",
      "WHAT INFORMATION DOES\n",
      "INFORMATION IN HUMAN HISTORY\n",
      "INTERSUBJECTIVE ENTITIES\n",
      "THE POWER OF STORIES\n",
      "THE NOBLE LIE\n",
      "THE PERENNIAL DILEMMA\n",
      "TO KILL A LOAN\n",
      "BUREAUCRACY\n",
      "BUREAUCRACY AND THE SEARCH FOR TRUTH\n",
      "THE DEEP STATE\n",
      "THE BIOLOGICAL DRAMAS\n",
      "LET’S KILL ALL THE LAWYERS\n",
      "THE MIRACLE DOCUMENT\n",
      "TAKING HUMANS OUT OF THE LOOP\n",
      "THE INFALLIBLE TECHNOLOGY\n",
      "THE MAKING OF THE HEBREW BIBLE\n",
      "THE INSTITUTION STRIKES BACK\n",
      "THE SPLIT BIBLE\n",
      "THE ECHO CHAMBER\n",
      "PRINT, SCIENCE, AND WITCHES\n",
      "THE SPANISH INQUISITION TO THE RESCUE\n",
      "THE DISCOVERY OF IGNORANCE\n",
      "SELF-CORRECTING MECHANISMS\n",
      "THE DSM AND THE BIBLE\n",
      "PUBLISH OR PERISH\n",
      "THE LIMITS OF SELF-CORRECTION\n",
      "MAJORITY DICTATORSHIP\n",
      "THE PEOPLE VERSUS THE TRUTH\n",
      "THE POPULIST ASSAULT\n",
      "MEASURING THE STRENGTH OF DEMOCRACIES\n",
      "STONE AGE DEMOCRACIES\n",
      "CAESAR FOR PRESIDENT!\n",
      "MASS MEDIA MAKES MASS DEMOCRACY POSSIBLE\n",
      "THE TWENTIETH CENTURY: MASS DEMOCRACY, BUT ALSO MASS TOTALITARIANISM\n",
      "A BRIEF HISTORY OF TOTALITARIANISM\n",
      "SPARTA AND QIN\n",
      "THE TOTALITARIAN TRINITY\n",
      "TOTAL CONTROL\n",
      "THE KULAKS\n",
      "ONE BIG HAPPY SOVIET FAMILY\n",
      "PARTY AND CHURCH\n",
      "HOW INFORMATION FLOWS\n",
      "NOBODY’S PERFECT\n",
      "THE TECHNOLOGICAL PENDULUM\n",
      "LINKS IN THE CHAIN\n",
      "HACKING THE OPERATING SYSTEM OF HUMAN CIVILIZATION\n",
      "WHAT ARE THE IMPLICATIONS?\n",
      "TAKING RESPONSIBILITY\n",
      "RIGHT AND LEFT\n",
      "NO DETERMINISM\n",
      "SLEEPLESS AGENTS\n",
      "UNDER-THE-SKIN SURVEILLANCE\n",
      "THE END OF PRIVACY \n",
      "VARIETIES OF SURVEILLANCE\n",
      "THE SOCIAL CREDIT SYSTEM\n",
      "ALWAYS ON\n",
      "THE DICTATORSHIP OF THE LIKE\n",
      "BLAME THE HUMANS\n",
      "THE ALIGNMENT PROBLEM\n",
      "THE PAPER-CLIP NAPOLEON\n",
      "THE CORSICAN CONNECTION\n",
      "THE KANTIAN NAZI\n",
      "THE CALCULUS OF SUFFERING\n",
      "COMPUTER MYTHOLOGY\n",
      "THE NEW WITCHES\n",
      "COMPUTER BIAS\n",
      "THE NEW GODS?\n",
      "THE DEMOCRATIC WAY\n",
      "THE PACE OF DEMOCRACY\n",
      "THE CONSERVATIVE SUICIDE\n",
      "UNFATHOMABLE\n",
      "THE RIGHT TO AN EXPLANATION\n",
      "NOSEDIVE\n",
      "DIGITAL ANARCHY\n",
      "BAN THE BOTS\n",
      "THE FUTURE OF DEMOCRACY\n",
      "THE BOT PRISON\n",
      "ALGORITHMIC TAKEOVER\n",
      "THE DICTATOR’S DILEMMA\n",
      "THE RISE OF DIGITAL EMPIRES\n",
      "DATA COLONIALISM\n",
      "FROM WEB TO COCOON\n",
      "THE GLOBAL MIND-BODY SPLIT\n",
      "FROM CODE WAR TO HOT WAR\n",
      "THE GLOBAL BOND\n",
      "THE HUMAN CHOICE\n",
      "EXTINCTION OF THE SMARTEST\n",
      "PROLOGUE\n",
      "CHAPTER 1: WHAT IS INFORMATION?\n",
      "CHAPTER 2: STORIES: UNLIMITED CONNECTIONS\n",
      "CHAPTER 3: DOCUMENTS: THE BITE OF THE PAPER TIGERS\n",
      "CHAPTER 4: ERRORS: THE FANTASY OF INFALLIBILITY\n",
      "CHAPTER 5: DECISIONS: A BRIEF HISTORY OF DEMOCRACY AND TOTALITARIANISM\n",
      "CHAPTER 6: THE NEW MEMBERS: HOW COMPUTERS ARE DIFFERENT FROM PRINTING PRESSES\n",
      "CHAPTER 7: RELENTLESS: THE NETWORK IS ALWAYS ON\n",
      "CHAPTER 8: FALLIBLE: THE NETWORK IS OFTEN WRONG\n",
      "CHAPTER 9: DEMOCRACIES: CAN WE STILL HOLD A CONVERSATION?\n",
      "CHAPTER 10: TOTALITARIANISM: ALL POWER TO THE ALGORITHMS?\n",
      "CHAPTER 11: THE SILICON CURTAIN: GLOBAL EMPIRE OR GLOBAL SPLIT?\n",
      "EPILOGUE\n"
     ]
    }
   ],
   "source": [
    "from types import MethodType\n",
    "processor.C_function__set_section_types_by_classes_and_clean_text = MethodType(set_section_types_by_classes_and_clean_text, processor)\n",
    "\n",
    "processor.D_set_section_types_by_classes_and_clean_text()\n",
    "processor.D2_clearup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ce26f97-00b9-4d31-9ebd-65d3de25a654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 => ('paragraph', 'BY YUVAL NOAH HARARI', <p class=\"acmh-ac-pg\"><a id=\"_idTextAnchor002\"></a>BY YUVAL NOAH HARARI</p>)\n",
      "1 => ('paragraph', 'This is an uncorrected ebook file. Please do not quote for publication until you check your copy against the finished book.', <p class=\"disclaimer\"><a id=\"_idTextAnchor004\"></a>This is an uncorrected ebook file. Please do not quote for publication until you check your copy against the finished book.</p>)\n",
      "2 => ('paragraph', 'To Itzik with love, and to all who love wisdom.', <p class=\"dedf-ded-pg\"><a id=\"_idTextAnchor005\"></a>To Itzik with love, and to all who love wisdom.</p>)\n",
      "3 => ('paragraph', 'Contents', <p class=\"fmt-toc-pg\">Contents</p>)\n",
      "4 => ('title', 'Prologue', 'chapter', <p class=\"fmt-pro-pg\"><a id=\"_idTextAnchor006\"></a>Prologue</p>)\n",
      "5 => ('title', 'PART I', 'part', <p class=\"pn-part-pg\" id=\"_idParaDest-1\"><a id=\"_idTextAnchor007\"></a>PART I</p>)\n",
      "6 => ('title', 'CHAPTER 1', 'chapter', <p class=\"cn-chap-pg\" id=\"_idParaDest-2\"><a id=\"_idTextAnchor008\"></a>CHAPTER 1</p>)\n",
      "7 => ('title', 'CHAPTER 2', 'chapter', <p class=\"cn-chap-pg\" id=\"_idParaDest-3\"><a id=\"_idTextAnchor009\"></a>CHAPTER 2</p>)\n",
      "8 => ('title', 'CHAPTER 3', 'chapter', <p class=\"cn-chap-pg\" id=\"_idParaDest-4\"><a id=\"_idTextAnchor010\"></a>CHAPTER 3</p>)\n",
      "9 => ('title', 'CHAPTER 4', 'chapter', <p class=\"cn-chap-pg\" id=\"_idParaDest-5\"><a id=\"_idTextAnchor011\"></a>CHAPTER 4</p>)\n",
      "10 => ('title', 'CHAPTER 5', 'chapter', <p class=\"cn-chap-pg\" id=\"_idParaDest-6\"><a id=\"_idTextAnchor012\"></a>CHAPTER 5</p>)\n",
      "11 => ('title', 'PART II', 'part', <p class=\"pn-part-pg\" id=\"_idParaDest-7\"><a id=\"_idTextAnchor013\"></a>PART II</p>)\n",
      "12 => ('title', 'CHAPTER 6', 'chapter', <p class=\"cn-chap-pg\" id=\"_idParaDest-8\"><a id=\"_idTextAnchor014\"></a>CHAPTER 6</p>)\n",
      "13 => ('title', 'CHAPTER 7', 'chapter', <p class=\"cn-chap-pg\" id=\"_idParaDest-9\"><a id=\"_idTextAnchor015\"></a>CHAPTER 7</p>)\n",
      "14 => ('title', 'CHAPTER 8', 'chapter', <p class=\"cn-chap-pg\" id=\"_idParaDest-10\"><a id=\"_idTextAnchor016\"></a>CHAPTER 8</p>)\n",
      "15 => ('title', 'PART III', 'part', <p class=\"pn-part-pg\" id=\"_idParaDest-11\"><a id=\"_idTextAnchor017\"></a>PART III</p>)\n",
      "16 => ('title', 'CHAPTER 9', 'chapter', <p class=\"cn-chap-pg\" id=\"_idParaDest-12\"><a id=\"_idTextAnchor018\"></a>CHAPTER 9</p>)\n",
      "17 => ('title', 'CHAPTER 10', 'chapter', <p class=\"cn-chap-pg\" id=\"_idParaDest-13\"><a id=\"_idTextAnchor019\"></a>CHAPTER 10</p>)\n",
      "18 => ('title', 'CHAPTER 11', 'chapter', <p class=\"cn-chap-pg\" id=\"_idParaDest-14\"><a id=\"_idTextAnchor020\"></a>CHAPTER 11</p>)\n",
      "19 => ('title', 'Epilogue', 'part', <p class=\"ct-epl-pg\"><a id=\"_idTextAnchor021\"></a>Epilogue</p>)\n",
      "20 => ('paragraph', 'Acknowledgments', <p class=\"bmt-ack-pg\"><a id=\"_idTextAnchor022\"></a>Acknowledgments</p>)\n",
      "21 => ('title', 'Notes', 'part', <p class=\"bmt-nt-pg\"><a id=\"_idTextAnchor023\"></a>Notes</p>)\n",
      "22 => ('paragraph', 'ABOUT THE AUTHOR', <p class=\"atat-ata-pg\"><a id=\"_idTextAnchor024\"></a>ABOUT THE AUTHOR</p>)\n",
      "\n",
      "('title', 'Prologue', 'chapter', <p class=\"fmt-pro-pg\"><a id=\"_idTextAnchor006\"></a>Prologue</p>)\n",
      "('title', 'PART I', 'part', <p class=\"pn-part-pg\" id=\"_idParaDest-1\"><a id=\"_idTextAnchor007\"></a>PART I</p>)\n",
      "('title', 'CHAPTER 1', 'chapter', <p class=\"cn-chap-pg\" id=\"_idParaDest-2\"><a id=\"_idTextAnchor008\"></a>CHAPTER 1</p>)\n",
      "('title', 'CHAPTER 2', 'chapter', <p class=\"cn-chap-pg\" id=\"_idParaDest-3\"><a id=\"_idTextAnchor009\"></a>CHAPTER 2</p>)\n",
      "('title', 'CHAPTER 3', 'chapter', <p class=\"cn-chap-pg\" id=\"_idParaDest-4\"><a id=\"_idTextAnchor010\"></a>CHAPTER 3</p>)\n",
      "('title', 'CHAPTER 4', 'chapter', <p class=\"cn-chap-pg\" id=\"_idParaDest-5\"><a id=\"_idTextAnchor011\"></a>CHAPTER 4</p>)\n",
      "('title', 'CHAPTER 5', 'chapter', <p class=\"cn-chap-pg\" id=\"_idParaDest-6\"><a id=\"_idTextAnchor012\"></a>CHAPTER 5</p>)\n",
      "('title', 'PART II', 'part', <p class=\"pn-part-pg\" id=\"_idParaDest-7\"><a id=\"_idTextAnchor013\"></a>PART II</p>)\n",
      "('title', 'CHAPTER 6', 'chapter', <p class=\"cn-chap-pg\" id=\"_idParaDest-8\"><a id=\"_idTextAnchor014\"></a>CHAPTER 6</p>)\n",
      "('title', 'CHAPTER 7', 'chapter', <p class=\"cn-chap-pg\" id=\"_idParaDest-9\"><a id=\"_idTextAnchor015\"></a>CHAPTER 7</p>)\n",
      "('title', 'CHAPTER 8', 'chapter', <p class=\"cn-chap-pg\" id=\"_idParaDest-10\"><a id=\"_idTextAnchor016\"></a>CHAPTER 8</p>)\n",
      "('title', 'PART III', 'part', <p class=\"pn-part-pg\" id=\"_idParaDest-11\"><a id=\"_idTextAnchor017\"></a>PART III</p>)\n",
      "('title', 'CHAPTER 9', 'chapter', <p class=\"cn-chap-pg\" id=\"_idParaDest-12\"><a id=\"_idTextAnchor018\"></a>CHAPTER 9</p>)\n",
      "('title', 'CHAPTER 10', 'chapter', <p class=\"cn-chap-pg\" id=\"_idParaDest-13\"><a id=\"_idTextAnchor019\"></a>CHAPTER 10</p>)\n",
      "('title', 'CHAPTER 11', 'chapter', <p class=\"cn-chap-pg\" id=\"_idParaDest-14\"><a id=\"_idTextAnchor020\"></a>CHAPTER 11</p>)\n",
      "('title', 'Epilogue', 'part', <p class=\"ct-epl-pg\"><a id=\"_idTextAnchor021\"></a>Epilogue</p>)\n",
      "('title', 'Notes', 'part', <p class=\"bmt-nt-pg\"><a id=\"_idTextAnchor023\"></a>Notes</p>)\n"
     ]
    }
   ],
   "source": [
    "for i, c in enumerate(processor.parsed_chapters):\n",
    "    print(f\"{i} => {c[0]}\")\n",
    "\n",
    "print()\n",
    "\n",
    "processor.parsed_chapters = processor.parsed_chapters[4:20] + [processor.parsed_chapters[21]] \n",
    "\n",
    "for c in processor.parsed_chapters:\n",
    "    print(c[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "913c20d6-7661-4ca2-8159-fa79b2c43b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "organized_book = processor.E_organize_book_by_hierarchical_sections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a2273e4-fea5-4a6e-9184-1e8a0a1dc675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prologue\n",
      "PART I\n",
      "PART II\n",
      "PART III\n",
      "Epilogue\n",
      "Notes\n"
     ]
    }
   ],
   "source": [
    "for root in processor.hierarchical_organized_book:\n",
    "    print(root['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d4de310-1cec-43d5-ae47-5bed028a94da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For chapter Prologue found notes PROLOGUE\n",
      "Added 28 notes\n",
      "For chapter CHAPTER 1 - What Is Information? found notes CHAPTER 1: WHAT IS INFORMATION?\n",
      "Added 19 notes\n",
      "For chapter CHAPTER 2 - Stories: Unlimited Connections found notes CHAPTER 2: STORIES: UNLIMITED CONNECTIONS\n",
      "Added 27 notes\n",
      "For chapter CHAPTER 3 - Documents: The Bite of the Paper Tigers found notes CHAPTER 3: DOCUMENTS: THE BITE OF THE PAPER TIGERS\n",
      "Added 52 notes\n",
      "For chapter CHAPTER 4 - Errors: The Fantasy of Infallibility found notes CHAPTER 4: ERRORS: THE FANTASY OF INFALLIBILITY\n",
      "Added 117 notes\n",
      "For chapter CHAPTER 5 - Decisions: A Brief History of Democracy and Totalitarianism found notes CHAPTER 5: DECISIONS: A BRIEF HISTORY OF DEMOCRACY AND TOTALITARIANISM\n",
      "Added 126 notes\n",
      "For chapter CHAPTER 6 - The New Members: How Computers Are Different from Printing Presses found notes CHAPTER 6: THE NEW MEMBERS: HOW COMPUTERS ARE DIFFERENT FROM PRINTING PRESSES\n",
      "Added 55 notes\n",
      "For chapter CHAPTER 7 - Relentless: The Network Is Always On found notes CHAPTER 7: RELENTLESS: THE NETWORK IS ALWAYS ON\n",
      "Added 52 notes\n",
      "For chapter CHAPTER 8 - Fallible: The Network Is Often Wrong found notes CHAPTER 8: FALLIBLE: THE NETWORK IS OFTEN WRONG\n",
      "Added 70 notes\n",
      "For chapter CHAPTER 9 - Democracies: Can We Still Hold a Conversation? found notes CHAPTER 9: DEMOCRACIES: CAN WE STILL HOLD A CONVERSATION?\n",
      "Added 57 notes\n",
      "For chapter CHAPTER 10 - Totalitarianism: All Power to the Algorithms? found notes CHAPTER 10: TOTALITARIANISM: ALL POWER TO THE ALGORITHMS?\n",
      "Added 15 notes\n",
      "For chapter CHAPTER 11 - The Silicon Curtain: Global Empire or Global Split? found notes CHAPTER 11: THE SILICON CURTAIN: GLOBAL EMPIRE OR GLOBAL SPLIT?\n",
      "Added 65 notes\n"
     ]
    }
   ],
   "source": [
    "from thefuzz import fuzz\n",
    "NOTES_PER_CHAPTER = processor.hierarchical_organized_book[-1]['children']\n",
    "\n",
    "def get_notes_chapter(chapter_name):\n",
    "    match = []\n",
    "    for i, chap in enumerate(NOTES_PER_CHAPTER):\n",
    "        notes_chapter_name = chap['content']\n",
    "        match.append((i, fuzz.ratio(notes_chapter_name.lower(), chapter_name.lower()), notes_chapter_name.lower()))\n",
    "\n",
    "    sorted_by_ratio = sorted(match, key=lambda x: x[1])\n",
    "\n",
    "    chapter_notes = NOTES_PER_CHAPTER[sorted_by_ratio[-1][0]]\n",
    "\n",
    "    notes = chapter_notes['children']\n",
    "\n",
    "    clean_notes = []\n",
    "\n",
    "    for note in notes:\n",
    "\n",
    "        note_html = note['content_html'][0]\n",
    "        full_content = note['content']\n",
    "        note_id = note_html.find(class_=\"ennum\").get_text()\n",
    "\n",
    "        clean_notes.append({\n",
    "            \"id\": note_id,\n",
    "            \"content\": full_content\n",
    "        })\n",
    "\n",
    "    return {\"chapter\": chapter_notes['content'], \"notes\": clean_notes}\n",
    "\n",
    "\n",
    "def get_note(_id, notes):\n",
    "    #print(notes)\n",
    "    match = []\n",
    "    for i, note in enumerate(notes):\n",
    "        note_id = note['id']\n",
    "        match.append((i, fuzz.ratio(_id.lower(), note['id'].lower()), note['id'].lower()))\n",
    "    \n",
    "    sorted_by_ratio = sorted(match, key=lambda x: x[1])\n",
    "    \n",
    "    chosen_note = notes[sorted_by_ratio[-1][0]]\n",
    "    \n",
    "    #print(\"Looking for matches with \" + _id)\n",
    "    #for m in match:\n",
    "    #    print(f\"{m[-1]} ==> {m[1]}\")\n",
    "    #print(chosen_note)\n",
    "    #print()\n",
    "    return chosen_note\n",
    "\n",
    "def fill_notes_for_chapter(chapter):\n",
    "    chapter_title = chapter['content']\n",
    "    chapter_notes = get_notes_chapter(chapter_title)\n",
    "    print(f\"For chapter {chapter_title} found notes {chapter_notes['chapter']}\")\n",
    "    \n",
    "    for par_index, paragraph in enumerate(chapter['children']):\n",
    "        # Make modifications to each HTML content piece\n",
    "        for i, html in enumerate(paragraph['content_html']):\n",
    "            if type(html) == list:\n",
    "                html = html[0]\n",
    "            elements_with_note = html.find_all(class_='enref')\n",
    "            for el_note in elements_with_note:\n",
    "                note_id = el_note.get_text()\n",
    "                chosen_note = get_note(note_id, chapter_notes['notes'])\n",
    "                note_content = f\"[_NOTE_[{chosen_note['content']}]]\"\n",
    "                el_note.string = note_content\n",
    "            \n",
    "            # Update the original content_html with modified version\n",
    "            paragraph['content_html'][i] = html\n",
    "        \n",
    "        paragraph['content'] = [f\"{html.get_text()} \" for html in paragraph['content_html']]\n",
    "        chapter['children'][par_index] = paragraph\n",
    "    print(f\"Added {len(chapter_notes['notes'])} notes\")\n",
    "    return chapter\n",
    "\n",
    "def process_book_with_notes(book_structure):\n",
    "    \"\"\"\n",
    "    Recursively process the book structure and fill notes for chapters\n",
    "    Args:\n",
    "        book_structure (list/dict): The hierarchical book structure\n",
    "    Returns:\n",
    "        The processed book structure with filled notes\n",
    "    \"\"\"\n",
    "    if isinstance(book_structure, list):\n",
    "        return [process_book_with_notes(item) for item in book_structure]\n",
    "    \n",
    "    if not isinstance(book_structure, dict):\n",
    "        return book_structure\n",
    "    \n",
    "    # Process current node\n",
    "    if book_structure.get('type') == 'title' and book_structure.get('subtype') == 'chapter':\n",
    "        # This is a chapter, apply the note filling\n",
    "        try:\n",
    "            return fill_notes_for_chapter(book_structure)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing chapter {book_structure.get('content')}: {str(e)}\")\n",
    "            return book_structure\n",
    "    \n",
    "    # Process children if they exist\n",
    "    if 'children' in book_structure and book_structure['children']:\n",
    "        book_structure['children'] = process_book_with_notes(book_structure['children'])\n",
    "    \n",
    "    return book_structure\n",
    "\n",
    "# To use the function:\n",
    "processor.hierarchical_organized_book = process_book_with_notes(processor.hierarchical_organized_book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63a5b8d8-594c-487b-abc8-3aee7a23dd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_key=\"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\"\n",
    "summarizer = EPUBSummarizerHierarchical(\n",
    "    title=\"Nexus by Yuval Noah Harari\", \n",
    "    organized_book=processor.hierarchical_organized_book,\n",
    "    openai_key=openai_key,\n",
    "    use_cache=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4540807f-4eb3-40a0-b6d4-03006be35c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting book processing...\n",
      "Prologue\n",
      "\tTHE NAIVE VIEW OF INFORMATION \n",
      "\tGOOGLE VERSUS GOETHE \n",
      "\tWEAPONIZING INFORMATION \n",
      "\tTHE ROAD AHEAD \n",
      "PART I\n",
      "\tCHAPTER 1 - What Is Information?\n",
      "\t\tWHAT IS TRUTH? \n",
      "\t\tWHAT INFORMATION DOES \n",
      "\t\tINFORMATION IN HUMAN HISTORY \n",
      "\tCHAPTER 2 - Stories: Unlimited Connections\n",
      "\t\tINTERSUBJECTIVE ENTITIES \n",
      "\t\tTHE POWER OF STORIES \n",
      "\t\tTHE NOBLE LIE \n",
      "\t\tTHE PERENNIAL DILEMMA \n",
      "\tCHAPTER 3 - Documents: The Bite of the Paper Tigers\n",
      "\t\tTO KILL A LOAN \n",
      "\t\tBUREAUCRACY \n",
      "\t\tBUREAUCRACY AND THE SEARCH FOR TRUTH \n",
      "\t\tTHE DEEP STATE \n",
      "\t\tTHE BIOLOGICAL DRAMAS \n",
      "\t\tLET’S KILL ALL THE LAWYERS \n",
      "\t\tTHE MIRACLE DOCUMENT \n",
      "\tCHAPTER 4 - Errors: The Fantasy of Infallibility\n",
      "\t\tTAKING HUMANS OUT OF THE LOOP \n",
      "\t\tTHE INFALLIBLE TECHNOLOGY \n",
      "\t\tTHE MAKING OF THE HEBREW BIBLE \n",
      "\t\tTHE INSTITUTION STRIKES BACK \n",
      "\t\tTHE SPLIT BIBLE \n",
      "\t\tTHE ECHO CHAMBER \n",
      "\t\tPRINT, SCIENCE, AND WITCHES \n",
      "\t\tTHE SPANISH INQUISITION TO THE RESCUE \n",
      "\t\tTHE DISCOVERY OF IGNORANCE \n",
      "\t\tSELF-CORRECTING MECHANISMS \n",
      "\t\tTHE DSM AND THE BIBLE \n",
      "\t\tPUBLISH OR PERISH \n",
      "\t\tTHE LIMITS OF SELF-CORRECTION \n",
      "\tCHAPTER 5 - Decisions: A Brief History of Democracy and Totalitarianism\n",
      "\t\tMAJORITY DICTATORSHIP \n",
      "\t\tTHE PEOPLE VERSUS THE TRUTH \n",
      "\t\tTHE POPULIST ASSAULT \n",
      "\t\tMEASURING THE STRENGTH OF DEMOCRACIES \n",
      "\t\tSTONE AGE DEMOCRACIES \n",
      "\t\tCAESAR FOR PRESIDENT! \n",
      "\t\tMASS MEDIA MAKES MASS DEMOCRACY POSSIBLE \n",
      "\t\tTHE TWENTIETH CENTURY: MASS DEMOCRACY, BUT ALSO MASS TOTALITARIANISM \n",
      "\t\tA BRIEF HISTORY OF TOTALITARIANISM \n",
      "\t\tSPARTA AND QIN \n",
      "\t\tTHE TOTALITARIAN TRINITY \n",
      "\t\tTOTAL CONTROL \n",
      "\t\tTHE KULAKS \n",
      "\t\tONE BIG HAPPY SOVIET FAMILY \n",
      "\t\tPARTY AND CHURCH \n",
      "\t\tHOW INFORMATION FLOWS \n",
      "\t\tNOBODY’S PERFECT \n",
      "\t\tTHE TECHNOLOGICAL PENDULUM \n",
      "PART II\n",
      "\tCHAPTER 6 - The New Members: How Computers Are Different from Printing Presses\n",
      "\t\tLINKS IN THE CHAIN \n",
      "\t\tHACKING THE OPERATING SYSTEM OF HUMAN CIVILIZATION \n",
      "\t\tWHAT ARE THE IMPLICATIONS? \n",
      "\t\tTAKING RESPONSIBILITY \n",
      "\t\tRIGHT AND LEFT \n",
      "\t\tNO DETERMINISM \n",
      "\tCHAPTER 7 - Relentless: The Network Is Always On\n",
      "\t\tSLEEPLESS AGENTS \n",
      "\t\tUNDER-THE-SKIN SURVEILLANCE \n",
      "\t\tTHE END OF PRIVACY  \n",
      "\t\tVARIETIES OF SURVEILLANCE \n",
      "\t\tTHE SOCIAL CREDIT SYSTEM \n",
      "\t\tALWAYS ON \n",
      "\tCHAPTER 8 - Fallible: The Network Is Often Wrong\n",
      "\t\tTHE DICTATORSHIP OF THE LIKE \n",
      "\t\tBLAME THE HUMANS \n",
      "\t\tTHE ALIGNMENT PROBLEM \n",
      "\t\tTHE PAPER-CLIP NAPOLEON \n",
      "\t\tTHE CORSICAN CONNECTION \n",
      "\t\tTHE KANTIAN NAZI \n",
      "\t\tTHE CALCULUS OF SUFFERING \n",
      "\t\tCOMPUTER MYTHOLOGY \n",
      "\t\tTHE NEW WITCHES \n",
      "\t\tCOMPUTER BIAS \n",
      "\t\tTHE NEW GODS? \n",
      "PART III\n",
      "\tCHAPTER 9 - Democracies: Can We Still Hold a Conversation?\n",
      "\t\tTHE DEMOCRATIC WAY \n",
      "\t\tTHE PACE OF DEMOCRACY \n",
      "\t\tTHE CONSERVATIVE SUICIDE \n",
      "\t\tUNFATHOMABLE \n",
      "\t\tTHE RIGHT TO AN EXPLANATION \n",
      "\t\tNOSEDIVE \n",
      "\t\tDIGITAL ANARCHY \n",
      "\t\tBAN THE BOTS \n",
      "\t\tTHE FUTURE OF DEMOCRACY \n",
      "\tCHAPTER 10 - Totalitarianism: All Power to the Algorithms?\n",
      "\t\tTHE BOT PRISON \n",
      "\t\tALGORITHMIC TAKEOVER \n",
      "\t\tTHE DICTATOR’S DILEMMA \n",
      "\tCHAPTER 11 - The Silicon Curtain: Global Empire or Global Split?\n",
      "\t\tTHE RISE OF DIGITAL EMPIRES \n",
      "\t\tDATA COLONIALISM \n",
      "\t\tFROM WEB TO COCOON \n",
      "\t\tTHE GLOBAL MIND-BODY SPLIT \n",
      "\t\tFROM CODE WAR TO HOT WAR \n",
      "\t\tTHE GLOBAL BOND \n",
      "\t\tTHE HUMAN CHOICE \n",
      "Epilogue\n",
      "\tEXTINCTION OF THE SMARTEST\n",
      "Skipping -> Notes\n",
      "Book processing complete.\n",
      "This took 932.2111656665802 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "#18.59$\n",
    "start = time.time()\n",
    "summarized_book = summarizer.process_book(titles_to_ignore=['Notes'])\n",
    "end = time.time()\n",
    "\n",
    "print(f\"This took {end - start} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06609ae0-5889-4dc5-9a26-bf1959b65a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This took 11.337514638900757 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "summarizer.create_global_summary(subtypes_to_use=['part', 'chapter'])\n",
    "end = time.time()\n",
    "print(f\"This took {end - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "742dc172-6b73-4787-a7f4-a7c80e999d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The book \"Nexus\" by Yuval Noah Harari serves as a profound inquiry into the state of humanity as it grapples with the rapid advancements in information technology, particularly artificial intelligence. Beginning with the premise that while our species is named Homo sapiens, denoting wisdom, recent history reveals a different picture—one marked by existential threats like ecological collapse and authoritarian regimes fueled by misinformation. Harari emphasizes that despite our vast accumulation of knowledge, fundamental questions regarding identity, truth, and well-being remain unanswered, leading to societal delusions and disarray.\\n\\nAs the narrative unfolds, Harari emphasizes the critical role of information and myth-making in human society. He posits that information is not merely about factual accuracy; it serves essential social functions that bind communities together, often through shared narratives rather than unambiguous truths. This premise sets the stage for his exploration of how humans have utilized storytelling as a powerful tool for cooperation, enabling large-scale social connections that transcend personal relationships. Through compelling examples, Harari illustrates how narratives shape identities, beliefs, and societal structures, becoming instruments for both unity and conflict, as seen in the dynamics of nationalism and historical injustices.\\n\\nThe book draws a clear distinction between various forms of information, from stories to documents, tackling the complexities inherent in bureaucracy and governance. Harari explains how written records evolved as societies transitioned from oral traditions, enabling more sophisticated systems of administration while raising questions about the portrayal of truth versus the necessity for order. He exposes the inherent fallibility of human systems, whether relying on bureaucratic processes or holy texts, touching on how institutional authority often suppresses dissent and varied interpretations in the pursuit of social cohesion.\\n\\nAs the examination progresses, Harari scrutinizes the emerging capabilities of AI and their implications for democracy and totalitarianism. He discusses how algorithmic decision-making represents a significant departure from traditional power structures, illustrating cases where social media has fueled violence and misinformation, such as during the Rohingya crisis in Myanmar. This reflection leads to broader considerations about the accelerating role of surveillance and data collection in shaping contemporary societies, questioning the nature of privacy and autonomy in modern governance.\\n\\nHarari\\'s narrative delves into the historical evolution of both democratic and authoritarian regimes, demonstrating how information control plays a foundational role in maintaining power. He warns of the potential dangers as technologies evolve, posing existential threats that transcend national borders, echoing past imperial ambitions exacerbated by the global landscape of information dominance. A significant theme throughout the discussion is the profound interconnectedness of modern societies, which, while providing opportunities for collaboration, also heighten the risks of digital divides and authoritarian practices.\\n\\nIn closing, Harari advocates for conscious engagement with the unfolding AI revolution, warning against the seduction of simplistic narratives—whether optimistic or pessimistic—about the role of technology in human interactions. He emphasizes the need for resilient and self-correcting information networks that prioritize truth over order, underscoring the enduring complexities of power dynamics. The future of humanity, as outlined in \"Nexus,\" hinges on our collective responses to these challenges, illuminating a path toward either sustainable evolution or catastrophic failure.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer.global_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34bfc95c-6455-453f-b239-844df5dd6dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Prologue\n",
      "\tProcessing: THE NAIVE VIEW OF INFORMATION \n",
      "\tProcessing: GOOGLE VERSUS GOETHE \n",
      "\tProcessing: WEAPONIZING INFORMATION \n",
      "\tProcessing: THE ROAD AHEAD \n",
      "Processing: PART I\n",
      "\tProcessing: CHAPTER 1 - What Is Information?\n",
      "\t\tProcessing: WHAT IS TRUTH? \n",
      "\t\tProcessing: WHAT INFORMATION DOES \n",
      "\t\tProcessing: INFORMATION IN HUMAN HISTORY \n",
      "\tProcessing: CHAPTER 2 - Stories: Unlimited Connections\n",
      "\t\tProcessing: INTERSUBJECTIVE ENTITIES \n",
      "\t\tProcessing: THE POWER OF STORIES \n",
      "\t\tProcessing: THE NOBLE LIE \n",
      "\t\tProcessing: THE PERENNIAL DILEMMA \n",
      "\tProcessing: CHAPTER 3 - Documents: The Bite of the Paper Tigers\n",
      "\t\tProcessing: TO KILL A LOAN \n",
      "\t\tProcessing: BUREAUCRACY \n",
      "\t\tProcessing: BUREAUCRACY AND THE SEARCH FOR TRUTH \n",
      "\t\tProcessing: THE DEEP STATE \n",
      "\t\tProcessing: THE BIOLOGICAL DRAMAS \n",
      "\t\tProcessing: LET’S KILL ALL THE LAWYERS \n",
      "\t\tProcessing: THE MIRACLE DOCUMENT \n",
      "\tProcessing: CHAPTER 4 - Errors: The Fantasy of Infallibility\n",
      "\t\tProcessing: TAKING HUMANS OUT OF THE LOOP \n",
      "\t\tProcessing: THE INFALLIBLE TECHNOLOGY \n",
      "\t\tProcessing: THE MAKING OF THE HEBREW BIBLE \n",
      "\t\tProcessing: THE INSTITUTION STRIKES BACK \n",
      "\t\tProcessing: THE SPLIT BIBLE \n",
      "\t\tProcessing: THE ECHO CHAMBER \n",
      "\t\tProcessing: PRINT, SCIENCE, AND WITCHES \n",
      "\t\tProcessing: THE SPANISH INQUISITION TO THE RESCUE \n",
      "\t\tProcessing: THE DISCOVERY OF IGNORANCE \n",
      "\t\tProcessing: SELF-CORRECTING MECHANISMS \n",
      "\t\tProcessing: THE DSM AND THE BIBLE \n",
      "\t\tProcessing: PUBLISH OR PERISH \n",
      "\t\tProcessing: THE LIMITS OF SELF-CORRECTION \n",
      "\tProcessing: CHAPTER 5 - Decisions: A Brief History of Democracy and Totalitarianism\n",
      "\t\tProcessing: MAJORITY DICTATORSHIP \n",
      "\t\tProcessing: THE PEOPLE VERSUS THE TRUTH \n",
      "\t\tProcessing: THE POPULIST ASSAULT \n",
      "\t\tProcessing: MEASURING THE STRENGTH OF DEMOCRACIES \n",
      "\t\tProcessing: STONE AGE DEMOCRACIES \n",
      "\t\tProcessing: CAESAR FOR PRESIDENT! \n",
      "\t\tProcessing: MASS MEDIA MAKES MASS DEMOCRACY POSSIBLE \n",
      "\t\tProcessing: THE TWENTIETH CENTURY: MASS DEMOCRACY, BUT ALSO MASS TOTALITARIANISM \n",
      "\t\tProcessing: A BRIEF HISTORY OF TOTALITARIANISM \n",
      "\t\tProcessing: SPARTA AND QIN \n",
      "\t\tProcessing: THE TOTALITARIAN TRINITY \n",
      "\t\tProcessing: TOTAL CONTROL \n",
      "\t\tProcessing: THE KULAKS \n",
      "\t\tProcessing: ONE BIG HAPPY SOVIET FAMILY \n",
      "\t\tProcessing: PARTY AND CHURCH \n",
      "\t\tProcessing: HOW INFORMATION FLOWS \n",
      "\t\tProcessing: NOBODY’S PERFECT \n",
      "\t\tProcessing: THE TECHNOLOGICAL PENDULUM \n",
      "Processing: PART II\n",
      "\tProcessing: CHAPTER 6 - The New Members: How Computers Are Different from Printing Presses\n",
      "\t\tProcessing: LINKS IN THE CHAIN \n",
      "\t\tProcessing: HACKING THE OPERATING SYSTEM OF HUMAN CIVILIZATION \n",
      "\t\tProcessing: WHAT ARE THE IMPLICATIONS? \n",
      "\t\tProcessing: TAKING RESPONSIBILITY \n",
      "\t\tProcessing: RIGHT AND LEFT \n",
      "\t\tProcessing: NO DETERMINISM \n",
      "\tProcessing: CHAPTER 7 - Relentless: The Network Is Always On\n",
      "\t\tProcessing: SLEEPLESS AGENTS \n",
      "\t\tProcessing: UNDER-THE-SKIN SURVEILLANCE \n",
      "\t\tProcessing: THE END OF PRIVACY  \n",
      "\t\tProcessing: VARIETIES OF SURVEILLANCE \n",
      "\t\tProcessing: THE SOCIAL CREDIT SYSTEM \n",
      "\t\tProcessing: ALWAYS ON \n",
      "\tProcessing: CHAPTER 8 - Fallible: The Network Is Often Wrong\n",
      "\t\tProcessing: THE DICTATORSHIP OF THE LIKE \n",
      "\t\tProcessing: BLAME THE HUMANS \n",
      "\t\tProcessing: THE ALIGNMENT PROBLEM \n",
      "\t\tProcessing: THE PAPER-CLIP NAPOLEON \n",
      "\t\tProcessing: THE CORSICAN CONNECTION \n",
      "\t\tProcessing: THE KANTIAN NAZI \n",
      "\t\tProcessing: THE CALCULUS OF SUFFERING \n",
      "\t\tProcessing: COMPUTER MYTHOLOGY \n",
      "\t\tProcessing: THE NEW WITCHES \n",
      "\t\tProcessing: COMPUTER BIAS \n",
      "\t\tProcessing: THE NEW GODS? \n",
      "Processing: PART III\n",
      "\tProcessing: CHAPTER 9 - Democracies: Can We Still Hold a Conversation?\n",
      "\t\tProcessing: THE DEMOCRATIC WAY \n",
      "\t\tProcessing: THE PACE OF DEMOCRACY \n",
      "\t\tProcessing: THE CONSERVATIVE SUICIDE \n",
      "\t\tProcessing: UNFATHOMABLE \n",
      "\t\tProcessing: THE RIGHT TO AN EXPLANATION \n",
      "\t\tProcessing: NOSEDIVE \n",
      "\t\tProcessing: DIGITAL ANARCHY \n",
      "\t\tProcessing: BAN THE BOTS \n",
      "\t\tProcessing: THE FUTURE OF DEMOCRACY \n",
      "\tProcessing: CHAPTER 10 - Totalitarianism: All Power to the Algorithms?\n",
      "\t\tProcessing: THE BOT PRISON \n",
      "\t\tProcessing: ALGORITHMIC TAKEOVER \n",
      "\t\tProcessing: THE DICTATOR’S DILEMMA \n",
      "\tProcessing: CHAPTER 11 - The Silicon Curtain: Global Empire or Global Split?\n",
      "\t\tProcessing: THE RISE OF DIGITAL EMPIRES \n",
      "\t\tProcessing: DATA COLONIALISM \n",
      "\t\tProcessing: FROM WEB TO COCOON \n",
      "\t\tProcessing: THE GLOBAL MIND-BODY SPLIT \n",
      "\t\tProcessing: FROM CODE WAR TO HOT WAR \n",
      "\t\tProcessing: THE GLOBAL BOND \n",
      "\t\tProcessing: THE HUMAN CHOICE \n",
      "Processing: Epilogue\n",
      "\tProcessing: EXTINCTION OF THE SMARTEST\n",
      "This took -0.2002568244934082 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "summarizer.create_contextual_summaries()\n",
    "nd = time.time()\n",
    "print(f\"This took {end - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62e91ca2-bf49-483d-9b3d-156ae91a86ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "class StructuredEPUBExporter:\n",
    "    def __init__(self, summarizer):\n",
    "        self.summarizer = summarizer\n",
    "        self.css_template = \"\"\"\n",
    "        /* Page setup */\n",
    "        @page { \n",
    "            size: A4;\n",
    "            margin: 1.5cm;\n",
    "            @top-center {\n",
    "                content: string(chapter);\n",
    "            }\n",
    "            @bottom-center {\n",
    "                content: counter(page);\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        /* Print-specific settings */\n",
    "        @media print {\n",
    "            .new-chapter {\n",
    "                page-break-before: always;\n",
    "            }\n",
    "            \n",
    "            .avoid-break {\n",
    "                page-break-inside: avoid;\n",
    "            }\n",
    "            \n",
    "            .keep-with-next {\n",
    "                page-break-after: avoid;\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        body {\n",
    "            font-family: \"Times New Roman\", Times, serif;\n",
    "            font-size: 12pt;\n",
    "            line-height: 1.5;\n",
    "            max-width: 100%;\n",
    "            margin: 0 auto;\n",
    "            padding: 10px;\n",
    "            counter-reset: page 1;\n",
    "            box-sizing: border-box;\n",
    "        }\n",
    "        \n",
    "        /* Title page specific */\n",
    "        .title-page {\n",
    "            page-break-inside: avoid !important;\n",
    "            page-break-after: always;\n",
    "            margin-bottom: 40px;\n",
    "            min-height: 50vh; \n",
    "        }\n",
    "        \n",
    "        .title-page h1 {\n",
    "            page-break-before: avoid !important;\n",
    "        }\n",
    "        \n",
    "        .title-page .summary-container {\n",
    "            page-break-before: avoid !important;\n",
    "            margin-top: 40px;\n",
    "        }\n",
    "        \n",
    "        /* Headers with print considerations */\n",
    "        h1, h2, h3, h4, h5, h6 { \n",
    "            page-break-after: avoid !important;\n",
    "        }\n",
    "        \n",
    "        /* Title followed by first paragraph or div should stay together */\n",
    "        h1 + p, h2 + p, h3 + p, h4 + p, h5 + p, h6 + p,\n",
    "        h1 + div, h2 + div, h3 + div, h4 + div, h5 + div, h6 + div {\n",
    "            page-break-before: avoid !important;\n",
    "        }\n",
    "        \n",
    "        /* Keep header groups together */\n",
    "        .header-group {\n",
    "            page-break-inside: avoid !important;\n",
    "        }\n",
    "\n",
    "        /* Headers specific styling */\n",
    "        h1 { \n",
    "            font-size: 24pt; \n",
    "            text-align: center; \n",
    "            margin: 40px 0 20px;\n",
    "            string-set: chapter content();\n",
    "            page-break-before: always;\n",
    "            border-bottom: 3px double #000;\n",
    "            padding-bottom: 20px;\n",
    "        }\n",
    "        \n",
    "        /* Part headers */\n",
    "        h2 { \n",
    "            font-size: 18pt; \n",
    "            margin-top: 40px;\n",
    "            margin-bottom: 30px;\n",
    "            page-break-after: avoid;\n",
    "            text-align: center;\n",
    "            color: #2c3e50;\n",
    "            border-bottom: 2px solid #2c3e50;\n",
    "            padding-bottom: 15px;\n",
    "            text-transform: uppercase;\n",
    "            letter-spacing: 2px;\n",
    "        }\n",
    "        \n",
    "        .summary-container h2 { \n",
    "            font-size: 22pt; \n",
    "            margin-top: 5px;\n",
    "            margin-bottom: 15px;\n",
    "            page-break-after: avoid;\n",
    "            text-align: center;\n",
    "            color: #2c3e50;\n",
    "            border-bottom: 2px solid #2c3e50;\n",
    "            padding-bottom: 15px;\n",
    "            text-transform: uppercase;\n",
    "            letter-spacing: 2px;\n",
    "        }\n",
    "        \n",
    "        /* Chapter headers */\n",
    "        h3 { \n",
    "            font-size: 16pt; \n",
    "            margin-top: 35px;\n",
    "            margin-bottom: 20px;\n",
    "            page-break-after: avoid;\n",
    "            color: #34495e;\n",
    "            background-color: #f8f9fa;\n",
    "            padding: 10px 15px;\n",
    "        }\n",
    "        \n",
    "        /* Content containers */\n",
    "        .overview-index {\n",
    "            margin: 20px 0;\n",
    "            padding: 15px;\n",
    "            page-break-inside: avoid;\n",
    "        }\n",
    "        \n",
    "        .overview-index ul {\n",
    "            list-style-type: none;\n",
    "            padding-left: 20px;\n",
    "        }\n",
    "        \n",
    "        .overview-index li {\n",
    "            margin: 10px 0;\n",
    "        }\n",
    "        \n",
    "        .summary-container {\n",
    "            margin: 10px 0;\n",
    "            padding: 5px 20px;\n",
    "            background-color: #f8f8f8;\n",
    "            border-left: 1px solid #333;\n",
    "            page-break-inside: avoid;\n",
    "        }\n",
    "        \n",
    "        .part-summary {\n",
    "            background-color: #f8f9fa;\n",
    "            border: 1px solid #2c3e50;\n",
    "            border-radius: 8px;\n",
    "            margin: 10px 0;\n",
    "            padding: 5px;\n",
    "            page-break-before: avoid !important;\n",
    "            page-break-inside: avoid !important;\n",
    "            box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n",
    "        }\n",
    "        \n",
    "        .chapter-summary {\n",
    "            background-color: #fff;\n",
    "            border-left: 1px solid #34495e;\n",
    "            margin: 5px 0;\n",
    "            padding: 5px;\n",
    "            page-break-before: avoid !important;\n",
    "            page-break-inside: avoid !important;\n",
    "            box-shadow: 0 1px 3px rgba(0,0,0,0.05);\n",
    "        }\n",
    "        \n",
    "        .page-break { \n",
    "            page-break-before: always; \n",
    "            height: 0;\n",
    "            margin: 0;\n",
    "            padding: 0;\n",
    "            visibility: hidden;\n",
    "        }\n",
    "        \"\"\"\n",
    "\n",
    "    def process_markdown(self, text: str) -> str:\n",
    "        try:\n",
    "            md = markdown.Markdown(extensions=['extra'])\n",
    "            return md.convert(text)\n",
    "        except Exception as e:\n",
    "            return f\"<p>Error processing content: {text}</p>\"\n",
    "\n",
    "    def generate_overview_index(self) -> Tuple[str, List[Dict]]:\n",
    "        index_html = ['<h1>Parts and Chapters Overview</h1>', '<div class=\"overview-index\">']\n",
    "        chapters_info = []\n",
    "        \n",
    "        has_parts = any(\n",
    "            node.get('subtype') == 'part' \n",
    "            for node in self.summarizer.summarized_book\n",
    "        )\n",
    "        \n",
    "        if has_parts:\n",
    "            index_html.append('<ul>')\n",
    "            for node in self.summarizer.summarized_book:\n",
    "                if node.get('subtype') == 'part':\n",
    "                    index_html.append(f'<li><strong>{node[\"content\"]}</strong>')\n",
    "                    if node.get('children'):\n",
    "                        index_html.append('<ul>')\n",
    "                        for child in node['children']:\n",
    "                            if child.get('subtype') == 'chapter':\n",
    "                                index_html.append(f'<li>{child[\"content\"]}</li>')\n",
    "                                chapters_info.append(child)\n",
    "                        index_html.append('</ul>')\n",
    "                    index_html.append('</li>')\n",
    "            index_html.append('</ul>')\n",
    "        else:\n",
    "            index_html.append('<ul>')\n",
    "            for node in self.summarizer.summarized_book:\n",
    "                if node.get('subtype') == 'chapter':\n",
    "                    index_html.append(f'<li>{node[\"content\"]}</li>')\n",
    "                    chapters_info.append(node)\n",
    "            index_html.append('</ul>')\n",
    "            \n",
    "        index_html.append('</div>')\n",
    "        return '\\n'.join(index_html), chapters_info\n",
    "\n",
    "    def generate_overview_content(self, chapters_info: List[Dict]) -> str:\n",
    "        content_html = []\n",
    "        \n",
    "        has_parts = any(\n",
    "            node.get('subtype') == 'part' \n",
    "            for node in self.summarizer.summarized_book\n",
    "        )\n",
    "        \n",
    "        if has_parts:\n",
    "            for node in self.summarizer.summarized_book:\n",
    "                if node.get('subtype') == 'part':\n",
    "                    content_html.append('<div class=\"header-group\">')\n",
    "                    \n",
    "                    if node.get('summary'):\n",
    "                        content_html.append('<div class=\"part-summary\">')\n",
    "                        content_html.append(f'<h2>{node[\"content\"]}</h2>')\n",
    "                        content_html.append(f'{self.process_markdown(node[\"summary\"][\"text\"])}')\n",
    "                        content_html.append('</div>')\n",
    "                    content_html.append('</div>')\n",
    "                    \n",
    "                    for child in node.get('children', []):\n",
    "                        if child.get('subtype') == 'chapter':\n",
    "                            content_html.append('<div class=\"header-group\">')\n",
    "                            \n",
    "                            if child.get('summary'):\n",
    "                                content_html.append('<div class=\"chapter-summary\">')\n",
    "                                content_html.append(f'<h3>{child[\"content\"]}</h3>')\n",
    "                                content_html.append(f'{self.process_markdown(child[\"summary\"][\"text\"])}')\n",
    "                                content_html.append('</div>')\n",
    "                            content_html.append('</div>')\n",
    "                    content_html.append('<div class=\"page-break\"></div>')\n",
    "        else:\n",
    "            for chapter in chapters_info:\n",
    "                content_html.append('<div class=\"header-group\">')\n",
    "                content_html.append(f'<h2>{chapter[\"content\"]}</h2>')\n",
    "                if chapter.get('summary'):\n",
    "                    content_html.append(\n",
    "                        f'<div class=\"chapter-summary\">{self.process_markdown(chapter[\"summary\"][\"text\"])}</div>'\n",
    "                    )\n",
    "                content_html.append('</div>')\n",
    "                content_html.append('<div class=\"page-break\"></div>')\n",
    "                \n",
    "        return '\\n'.join(content_html)\n",
    "\n",
    "    def export_overview_html(self, output_file: str = \"book_overview.html\") -> str:\n",
    "        overview_index, chapters_info = self.generate_overview_index()\n",
    "        overview_content = self.generate_overview_content(chapters_info)\n",
    "        \n",
    "        html = f\"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <title>{self.summarizer.book_title} - Overview</title>\n",
    "    <style>\n",
    "    {self.css_template}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"title-page\">\n",
    "        <h1>{self.summarizer.book_title}</h1>\n",
    "        <div class=\"summary-container\">\n",
    "            <h2>Book Summary</h2>\n",
    "            {self.process_markdown(self.summarizer.global_summary)}\n",
    "        </div>\n",
    "    </div>\n",
    "    \n",
    "    {overview_index}\n",
    "    \n",
    "    <div class=\"page-break\"></div>\n",
    "    \n",
    "    {overview_content}\n",
    "</body>\n",
    "</html>\"\"\"\n",
    "    \n",
    "        try:\n",
    "            with open(output_file, 'w', encoding='utf-8') as f:\n",
    "                f.write(html)\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error writing HTML file: {str(e)}\")\n",
    "            \n",
    "        return output_file\n",
    "\n",
    "    def has_detailed_summaries(self, chapter: Dict) -> bool:\n",
    "        \"\"\"\n",
    "        Check if a chapter has subsections with summaries.\n",
    "        \n",
    "        Args:\n",
    "            chapter: Dictionary containing chapter data\n",
    "            \n",
    "        Returns:\n",
    "            bool: True if chapter has subsections with summaries\n",
    "        \"\"\"\n",
    "        if not chapter.get('children'):\n",
    "            return False\n",
    "            \n",
    "        return any(\n",
    "            child.get('type') == 'title' and child.get('summary')\n",
    "            for child in chapter['children']\n",
    "        )\n",
    "\n",
    "    def generate_detailed_index(self, chapters_info: List[Dict]) -> str:\n",
    "        \"\"\"\n",
    "        Generate the detailed summaries index.\n",
    "        \n",
    "        Args:\n",
    "            chapters_info: List of chapter dictionaries\n",
    "            \n",
    "        Returns:\n",
    "            str: HTML string for detailed summaries index\n",
    "        \"\"\"\n",
    "        has_detailed = any(self.has_detailed_summaries(chapter) for chapter in chapters_info)\n",
    "        \n",
    "        if not has_detailed:\n",
    "            return '<h1>Detailed Chapter Summaries</h1>\\n<p class=\"note\">Chapters don\\'t have subsections thus detailed summary not available.</p>'\n",
    "            \n",
    "        index_html = ['<h1>Detailed Chapter Summaries</h1>', '<div class=\"overview-index\">', '<ul>']\n",
    "        \n",
    "        for chapter in chapters_info:\n",
    "            if self.has_detailed_summaries(chapter):\n",
    "                index_html.append(f'<li>{chapter[\"content\"]}</li>')\n",
    "        \n",
    "        index_html.extend(['</ul>', '</div>'])\n",
    "        return '\\n'.join(index_html)\n",
    "\n",
    "    def generate_detailed_content(self, chapters_info: List[Dict]) -> str:\n",
    "        \"\"\"\n",
    "        Generate the detailed chapter summaries content.\n",
    "        \n",
    "        Args:\n",
    "            chapters_info: List of chapter dictionaries\n",
    "            \n",
    "        Returns:\n",
    "            str: HTML string for detailed content\n",
    "        \"\"\"\n",
    "        content_html = []\n",
    "        has_detailed = False\n",
    "        \n",
    "        for chapter in chapters_info:\n",
    "            if self.has_detailed_summaries(chapter):\n",
    "                has_detailed = True\n",
    "                content_html.append('<div class=\"header-group\">')\n",
    "                content_html.append(f'<h2>{chapter[\"content\"]}</h2>')\n",
    "                \n",
    "                for section in chapter.get('children', []):\n",
    "                    if section.get('type') == 'title' and section.get('summary'):\n",
    "                        content_html.append(f'<h3>{section[\"content\"]}</h3>')\n",
    "                        content_html.append(\n",
    "                            f'<div class=\"section-summary\">{self.process_markdown(section[\"summary\"][\"text\"])}</div>'\n",
    "                        )\n",
    "                \n",
    "                content_html.append('</div>')\n",
    "                content_html.append('<div class=\"page-break\"></div>')\n",
    "                \n",
    "        if not has_detailed:\n",
    "            return ''\n",
    "            \n",
    "        return '\\n'.join(content_html)\n",
    "\n",
    "    def export_detailed_html(self, output_file: str = \"book_detailed.html\") -> str:\n",
    "        \"\"\"\n",
    "        Export the detailed chapter summaries to HTML.\n",
    "        \n",
    "        Args:\n",
    "            output_file: Path to save the HTML file\n",
    "            \n",
    "        Returns:\n",
    "            str: Path to the generated file\n",
    "        \"\"\"\n",
    "        # Generate overview index and collect chapter information\n",
    "        _, chapters_info = self.generate_overview_index()\n",
    "        detailed_index = self.generate_detailed_index(chapters_info)\n",
    "        detailed_content = self.generate_detailed_content(chapters_info)\n",
    "        \n",
    "        # Don't generate if there's no detailed content\n",
    "        if not detailed_content:\n",
    "            return \"\"\n",
    "        \n",
    "        # Combine everything into final HTML\n",
    "        html = f\"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <title>{self.summarizer.book_title} - Detailed Summaries</title>\n",
    "    <style>\n",
    "    {self.css_template}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"title-page\">\n",
    "        <h1>{self.summarizer.book_title}</h1>\n",
    "        <h2>Detailed Chapter Summaries</h2>\n",
    "    </div>\n",
    "    \n",
    "    {detailed_index}\n",
    "    \n",
    "    <div class=\"page-break\"></div>\n",
    "    \n",
    "    {detailed_content}\n",
    "</body>\n",
    "</html>\"\"\"\n",
    "    \n",
    "        # Write to file\n",
    "        try:\n",
    "            with open(output_file, 'w', encoding='utf-8') as f:\n",
    "                f.write(html)\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error writing HTML file: {str(e)}\")\n",
    "            \n",
    "        return output_file\n",
    "\n",
    "exporter = StructuredEPUBExporter(summarizer)\n",
    "output_file = exporter.export_overview_html('nexus_overview.html')\n",
    "output_file = exporter.export_detailed_html('nexus_detailed.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f1ed11-f183-4826-b314-285eba85fc5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
